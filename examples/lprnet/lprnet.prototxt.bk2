name: "lprnet"
layer {
    name: "data"
    type: "HDF5Data"
    top: "data"
    top: "label"
    include {
        phase: TRAIN
    }
    hdf5_data_param {
        source: "./data/captcha/trainning.list"
        batch_size: 523
    }
}
#w:94*24*1
layer {
    name: "data"
    type: "HDF5Data"
    top: "data"
    top: "label"
    include {
        phase: TEST
    }
    hdf5_data_param {
        source: "./data/captcha/testing.list"
        batch_size: 523
    }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
#w*h:48*16
layer {
	bottom: "conv0"
	top: "conv0"
	name: "bn_conv0"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
    include {
        phase: TRAIN
    }
}
layer{
    bottom:"conv0"
    top: "conv0"
    name: "bn_conv0"
    type: "BatchNorm"
    batch_norm_param{
        use_global_stats: true
    }
    include{
        phase: TEST
    }
}
layer {
	bottom: "conv0"
	top: "conv0"
	name: "scale_conv0"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}
layer {
  name: "relu0"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}
layer {
  name: "pool0"
  type: "Pooling"
  bottom: "conv0"
  top: "pool0"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
  }
}
### SMALL BASIC BLOCK ONE starts!!!###
layer {
  name: "sbb1"
  type: "Convolution"
  bottom: "pool0"
  top: "sbb1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    kernel_size: 1
    stride: 1
    pad: 0
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "convb_sbb1"
  type: "Convolution"
  bottom: "sbb1"
  top: "sbb1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    kernel_w: 3
    kernel_h: 1
    stride: 1
    pad_w: 1
    pad_h: 0
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "convc_sbb1"
  type: "Convolution"
  bottom: "sbb1"
  top: "sbb1"
  convolution_param {
    num_output: 16
    kernel_w: 1
    kernel_h: 3
    stride: 1
    pad_w: 1
    pad_h: 0
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "convd_sbb1"
  type: "Convolution"
  bottom: "sbb1"
  top: "sbb1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
    pad: 0
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
##SMALL BASIC BLOCK One ends!!!###
layer {
	bottom: "sbb1"
	top: "conv1"
	name: "bn_conv1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
    include {
        phase: TRAIN
    }
}
layer{
    bottom:"conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    batch_norm_param{
        use_global_stats: true
    }
    include{
        phase: TEST
    }
}
layer {
	bottom: "conv1"
	top: "conv1"
	name: "scale_conv1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride_w: 2
    stride_h: 1
    pad: 1
  }
}
#w*h:24*8
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
	bottom: "conv2"
	top: "conv2"
	name: "bn_conv2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
    include {
        phase: TRAIN
    }
}
layer{
    bottom:"conv2"
    top: "conv2"
    name: "bn_conv2"
    type: "BatchNorm"
    batch_norm_param{
        use_global_stats: true
    }
    include{
        phase: TEST
    }
}
layer {
	bottom: "conv2"
	top: "conv2"
	name: "scale_conv2"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
	bottom: "conv3"
	top: "conv3"
	name: "bn_conv3"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
    include {
        phase: TRAIN
    }
}
layer{
    bottom:"conv3"
    top: "conv3"
    name: "bn_conv3"
    type: "BatchNorm"
    batch_norm_param{
        use_global_stats: true
    }
    include{
        phase: TEST
    }
}
layer {
	bottom: "conv3"
	top: "conv3"
	name: "scale_conv3"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv3"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
#w*h:12*4
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
	bottom: "conv4"
	top: "conv4"
	name: "bn_conv4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
    include {
        phase: TRAIN
    }
}
layer {
    bottom: "conv4"
    top: "conv4"
    name: "bn_conv4"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }   
    include{
        phase: TEST
    }   
}
layer {
	bottom: "conv4"
	top: "conv4"
	name: "scale_conv4"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad_w: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
#12*2
layer {
	bottom: "conv5"
	top: "conv5"
	name: "bn_conv5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
    include {
        phase: TRAIN
    }
}
layer{
    bottom:"conv5"
    top: "conv5"
    name: "bn_conv5"
    type: "BatchNorm"
    batch_norm_param{
        use_global_stats: true
    }
    include{
        phase: TEST
    }
}
layer {
	bottom: "conv5"
	top: "conv5"
	name: "scale_conv5"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
	bottom: "conv6"
	top: "conv6"
	name: "bn_conv6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
    include {
        phase: TRAIN
    }
}
layer {
    bottom: "conv6"
    top: "conv6"
    name: "bn_conv6"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    include{
        phase: TEST
    }
} 
layer {
	bottom: "conv6"
	top: "conv6"
	name: "scale_conv6"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
    name: "reshape"
    type: "Reshape"
    bottom: "conv6"
    top: "reshape"
    reshape_param {
        shape {
        #n*c*(w*h)
            dim: 523
            dim: 512
            dim: 24
        }
    }
}
layer {
    name: "permuted_data"
    type: "Permute"
    bottom: "reshape"
    top: "permuted_data"
    #(w*h) * n * c
    permute_param {
        order: 2
        order: 0
        order: 1
    }
}
layer {
    name: "indicator"
    type: "ContinuationIndicator"
    top: "indicator"
    continuation_indicator_param {
        time_step:  24
        batch_size: 523
    }
}
layer {
    name: "lstm1"
    type: "LSTM"
    bottom: "permuted_data"
    bottom: "indicator"
    top: "lstm1"
    recurrent_param {
        num_output: 128
        weight_filler {
          type: "xavier"
        }
        bias_filler {
          type: "constant"
          value: 0
        }
    }
}
layer {
    name: "lstm2"
    type: "LSTM"
    bottom: "lstm1"
    bottom: "indicator"
    top: "lstm2"
    recurrent_param {
        num_output: 256
        weight_filler {
          type: "xavier"
        }
        bias_filler {
          type: "constant"
          value: 0
        }
    }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "lstm2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 75
	axis: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
	name: "ctc_loss"
	type: "CtcLoss"
	bottom: "fc1"
	bottom: "label"
	top: "ctc_loss"
	loss_weight: 1.0
	ctc_loss_param {
		blank_label: 74
		alphabet_size: 75
    	time_step: 24
	}
}

layer {
  name: "permute_fc"
  type: "Permute"
  bottom: "fc1"
  top: "premuted_fc"
  permute_param {
    order: 1
    order: 0
    order: 2
  }
}
layer {
  name: "accuracy"
  type: "LabelsequenceAccuracy"
  bottom: "premuted_fc"
  bottom: "label"
  top: "accuracy"
  labelsequence_accuracy_param {
    blank_label: 74
  }
}
